\chapter{Literature Review}
 In this chapter, we review the foundations and advanced algorithms for shortest path calculations, including preprocessing techniques. The section spans classical algorithms, advanced algorithms and recent advances in graph-optimization.
\section{Classical shortest path algorithms}
	\subsection{Breadth-first Search}
		\subsubsection{Introduction}
		Breadth-first search is a graph traversal algorithms invented by Konrad Zuse in 1945, that can also be used to find the shortest path from a source vertex to a destination vertex in an unweighted graph.
		
		\subsubsection{Algorithm}
			\begin{enumerate}
				\item Mark all vertices as unvisited.
				\item Assign $distance[u] = \infty$ for all vertices except the source vertex $s$, where $distance[s] = 0$.
				\item Use a queue to track vertices to explore. Start with the source vertex $s$.
				\item Dequeue a vertex $u$.
				\item For each neighbour $v$ of $u$, If $v$ is unvisited (i.e., $distance[v]=\infty$):
					\begin{itemize}
						\item Set $distance[v] = distance[u] + 1$.
						\item Mark $v$ as visited.
						\item Enqueue $v$.
					\end{itemize}
				\item The algorithm ends when the queue is empty. Unreachable vertices retain $distance = \infty$.
			\end{enumerate}
			This algorithm is mathematically predisposed to find the shortest path from a source vertex $s$ to every other vertex in the graph (see\textbf{ Appendix \ref{appendix:bfs:correctness}} for a formal proof).
		
		\subsubsection{Complexity}
			When finding the shortest path between a pair of vertices in a graph, the worst-case time complexity for the BFS algorithm is $O(V)$ for queue operations + $O(E)$ for edge processing, netting a worst-case time complexity of $O(V + E)$ (see \textbf{Appendix \ref{appendix:bfs:complexity}} for a formal proof). \medskip
			
			The space complexity for BFS is $O(V)$ since we use a queue to store the vertices yet to be explored.
		
		\subsubsection{Pros and Cons}
			\begin{itemize}
				\item The algorithm is simple and efficient for unweighted graphs.
				\item BFS works well for large, sparse graphs.
				\item BFS fails for shortest-path problems in weighted graphs, which are more useful when modelling real world scenarios.
			\end{itemize}
	\subsection{Bellman-ford Algorithm}
		\subsubsection{Introduction}
			The Bellman–Ford algorithm is a shortest-path algorithm that utilizes dynamic programming to compute shortest paths from a single source vertex to all of the other vertices in a weighted, directed graph. It was first published by Richard Bellman (1958) and Lester Ford Jr. (1956), hence its name.
		\subsubsection{Algorithm}
			\begin{enumerate}
				\item Create an array $distance$ of size $V$ to store the shortest path distances.
				\item Assign $distance[u] = \infty$ for all vertices except the source vertex $s$, where $distance[s] = 0$.
				\item Repeat $V - 1$ times:
					\begin{itemize}
						\item For each edge $(u,v) \in E$, if $distance[u] + w(u,v) < distance[v]$ update $distance[v]=distance[u]+w(u,v)$.
					\end{itemize}
				\item Now to detect a negative cycle, for each edge $(u,v) \in E$, if $distance[u] + w(u,v) < distance[v]$, report that a negative-weight cycle exists.
				\item If no negative-weight cycle is detected, Return the $distance$ array as the shortest path distances.
			\end{enumerate}
			Refer to \textbf{Appendix \ref{appendix:bellford:correctness}} for a formal proof of correctness of this algorithm.
		\subsubsection{Complexity}
			When finding the shortest path from a source vertex to every other vertex in a graph, the worst-case time complexity for the Bellman-Ford algorithm is $O(V \cdot E)$ (see \textbf{Appendix \ref{appendix:bellford:complexity}} for a formal proof). \medskip
			
			The space complexity for Bellman-Ford is $O(V)$ since we use an array of size $V$ to store all the shortest-path distances.
		\subsubsection{Pros and Cons}
			\begin{itemize}
				\item Suitable for applications requiring negative weight handling, in which case it can detect the existence of a negative cycle.
				\item The Bellman-Ford algorithm is more complex than Dijkstra's algorithm.
				\item Much slower compared to Dijkstra's algorithm.
			\end{itemize}
	\subsection{Dijkstra's Algorithm}
		\subsubsection{Introduction}
			Dijkstra's algorithm is a greedy algorithm used to find the shortest paths from a single source vertex to all other vertices in a weighted graph with non-negative edge weights. It was conceived by computer scientist Edsger W. Dijkstra in 1956 and published three years later.
		\subsubsection{Algorithm}
		\begin{enumerate}
			\item Create an array $distance$ of size $V$ to store the shortest path distances and a priority queue $Q$ containing all vertices, prioritized by $distance$.
			\item Assign $distance[u] = \infty$ for all vertices except the source vertex $s$, where $distance[s] = 0$.
			\item While $Q$ is not empty:
				\begin{itemize}
					\item Extract the vertex u u with the smallest distance distance from $Q$.
					\item For each neighbor $v$ of $u$, if $distance[u] + w(u,v) < distance[v]$: update $distance[v]=distance[u]+w(u,v)$ and the priority of $v$ in $Q$.
				\end{itemize}
			\item The algorithm ends when $Q$ is empty. The distance distance array contains the shortest path distances from $s$ to all other vertices.
		\end{enumerate}
			Refer to \textbf{Appendix \ref{appendix:dijkstra:correctness}} for a formal proof of correctness of this algorithm.
		\subsubsection{Complexity}
			When finding the shortest path from a source vertex to every other vertex in a graph, the worst-case time complexity for the Dijkstra's algorithm is $O((V+E)\log{V})$ using a binary heap or $O(V\log{V}+E)$ using a Fibonacci heap. (see \textbf{Appendix \ref{appendix:dijkstra:complexity}} for a formal proof). \medskip
			
			The space complexity for Dijkstra's is $O(V)$ since we use an array of size $V$ to store all the shortest-path distances.
		\subsubsection{Pros and Cons}
		\begin{itemize}
			\item Can cover a large area of a graph, which is useful when there are multiple target nodes.
			\item Can't calculate the shortest paths correctly if the graph has negative weights.
			\item Has linearithmetic complexity when implemented using a priority queue.
		\end{itemize}

\section{Advanced shortest path algorithms}
	\subsection{A* Search Algorithm}
		\subsubsection{Introduction}
			A* search is a heuristic-based algorithm used to find the shortest path from a start node to a goal node in a weighted graph. It combines the strengths of Dijkstra's algorithm (guaranteed shortest path) and greedy best-first search (efficient exploration using heuristics). It was first published by Peter Hart, Nils Nilsson, and Bertram Raphael at Stanford Research Institute in 1968.
		\subsubsection{Algorithm}
			\begin{enumerate}
				\item Create a priority queue $Q$ to store nodes to explore, prioritized by $f(v)=g(v)+h(v)$, where
					\begin{itemize}
						\item $g(v)$: Cost of the shortest path from $s$ to $v$ found so far.
						\item $h(v)$: Heuristic estimate of the cost from $v$ to $t$.
					\end{itemize}
				\item Set $g(s)=0$ and $f(s)=h(s)$.
				\item Insert $s$ into $Q$.
				\item Create a set $visited$ to track visited nodes
				\item While $Q$ is not empty:
					\begin{enumerate}
						\item Extract the node $u$ with the smallest $f(u)$ from $Q$.
						\item If $u=t$, return the path from $s$ to $t$.
						\item Mark $u$ as visited.
						\item For each neighbor $v$ of $u$, if $v$ is not visited:
							\begin{itemize}
								\item Compute $g_{tentative} = g(u) + w(u,v)$.
								\item If $g_{tentative} < g(v)$ or $v$ is not in $Q$:
									\begin{itemize}
										\item Update $g(v)=g_{tentative}$.
										\item Update $f(v)=g(v)+h(v)$.
										\item Insert $v$ into $Q$ (or update its priority if already in $Q$).
									\end{itemize}
							\end{itemize}
					\end{enumerate}
				\item If $Q$ becomes empty and the goal $t$ has not been reached, no path exists.
			\end{enumerate}
			A* search is correct if the heuristic $h(v)$ is admissible (never overestimates the true cost to the goal) and consistent (satisfies the triangle inequality: $h(u) \leq w(u,v)+h(v)$ for all edges $(u,v))$. For a formal proof of correctness, refer to \textbf{Appendix \ref{appendix:astar:correctness}}.
		\subsubsection{Complexity}
		Since A* Search is basically an 'informed' version of Dijkstra's algorithm, the space complexity for A* search is the same as for Dijkstra's, which is $O(V)$.
		The time complexity, however, depends on the heuristic function and is equal to Dijsktra's when the heuristic $h(v) = 0$.
		\subsubsection{Pros and Cons}
			\begin{itemize}
				\item Compared to uninformed search algorithms, A* explores significantly fewer nodes leading to faster search times. 
				\item By maintaining a priority queue, A* only needs to store a limited number of nodes in memory, making it suitable for large search spaces.
				\item Performance heavily depends on the quality of the heuristic function. Thus, A* search is not ideal when a good heuristic cannot be easily defined or when heuristic calculations are complicated.
			\end{itemize}
	\subsection{Bidirectional Search}
		\subsubsection{Introduction}
			Bidirectional Search is a graph traversal algorithm that explores a graph by simultaneously conducting two searches: one starting from the initial (source) node and moving forward, and another starting from the goal (target) node and moving backward. The two searches "meet" when a common node is detected in their exploration paths. This approach significantly reduces the search space compared to traditional unidirectional algorithms like Breadth-First Search (BFS) or Depth-First Search (DFS), making it particularly efficient for problems with well-defined start and goal states. Bidirectional Search is widely used in pathfinding applications, network routing, and puzzle-solving algorithms (e.g., 15-puzzle, Rubik’s Cube).
		\subsubsection{Algorithm}
		
		\subsection*{Initialization}
		\begin{itemize}
			\item Create two queues: \texttt{forward\_queue} (for the forward search from the start node) and \texttt{backward\_queue} (for the backward search from the goal node).
			\item Maintain two visited sets: \texttt{forward\_visited} and \texttt{backward\_visited}, to track explored nodes in each direction.
		\end{itemize}
		
		\subsection*{Search Execution}
		Expand nodes level-by-level from both directions, typically using BFS for optimal shortest-path guarantees.
		
		For each iteration:
		\begin{itemize}
			\item \textbf{Forward Search:} Dequeue a node from \texttt{forward\_queue}, mark it as visited in \texttt{forward\_visited}, and enqueue its unvisited neighbors.
			\item \textbf{Backward Search:} Dequeue a node from \texttt{backward\_queue}, mark it as visited in \texttt{backward\_visited}, and enqueue its unvisited predecessors (reverse neighbors).
		\end{itemize}
		
		\subsection*{Intersection Check}
		\begin{itemize}
			\item After each step, check if the current node in either direction exists in the opposite visited set.
			\item If an intersection node is found, terminate the search.
		\end{itemize}
		
		\subsection*{Path Reconstruction}
		Combine the path from the start node to the intersection node (forward path) and the path from the intersection node to the goal node to form the complete solution.
		
		Please refer to \textbf{ Appendix \ref{appendix:Bidirectional:correctness}} for a formal proof of correctness.
		
		\subsubsection{Complexity}
		
		\subsection*{Time Complexity}
		\begin{itemize}
			\item \textbf{Traditional BFS:} $O(b^d)$, where $b$ = branching factor, $d$ = depth of the goal.
			\item \textbf{Bidirectional Search:} $O(b^{d/2} + b^{d/2}) = O(b^{d/2})$.
			
			The reduction arises because both searches explore only half the depth.
		\end{itemize}
		
		\subsection*{Space Complexity}
		\begin{itemize}
			\item $O(b^{d/2})$ for each direction, totaling $O(b^{d/2})$. 
			\item More memory-efficient than unidirectional BFS ($O(b^d)$).
			
		\end{itemize}
	    Please refer to \textbf{ Appendix \ref{appendix:Bidirectional:complexity}} for a formal proof of complexity.
	    
	
		\subsubsection{Pros and Cons}
		\begin{enumerate}
			\item Bidirectional search is more efficient compared to traditional BFS and DFS because it reduces both time and space complexity exponentially.
			\item Guarantees the shortest path when using BFS.
			\item This algorithm works well for symmetric state spaces, providing a balanced search.
			\item It is scalable and suitable for large graphs with high branching factors.\\
			
			
			\item Bidirectional search requires explicit knowledge of the goal state, which may not always be possible.
			\item Managing two simultaneous searches increases implementation complexity.
			\item Handling predecessor tracking in directed graphs can be challenging.
			\item Frequent intersection checks introduce synchronization overhead during execution.
		\end{enumerate}
\section{Preprocessing techniques}
\subsection{Contraction Hierarchies}
	\subsubsection{Introduction}
	Contraction Hierarchies (CH) is a speed-up technique for shortest-path computations in large-scale graphs, particularly road networks. It preprocesses the graph to create a hierarchy of nodes, allowing queries to be answered significantly faster than traditional algorithms like Dijkstra's. The key idea is to iteratively ``contract'' less important nodes, adding shortcut edges to preserve shortest paths. During query processing, a bidirectional search is performed on the hierarchy, which drastically reduces the search space. CH is widely used in navigation systems, logistics, and route planning due to its efficiency and scalability.
	\subsubsection{Algorithm}
	\subsubsection*{Preprocessing Phase:}
	\begin{enumerate}
		\item \textbf{Node Ordering:} Assign a priority (importance) to each node based on a heuristic (e.g., edge difference, number of shortcuts added).
		\item \textbf{Node Contraction:} Iteratively contract nodes in increasing order of importance:
		\begin{itemize}
			\item Remove the node and add shortcuts between its neighbors to preserve shortest paths.
			\item Store the shortcuts and contracted nodes in the hierarchy.
		\end{itemize}
	\end{enumerate}
	
	\subsubsection*{Query Phase:}
	\begin{enumerate}
		\item \textbf{Bidirectional Search:} Perform a bidirectional Dijkstra search on the preprocessed graph:
		\begin{itemize}
			\item \textbf{Forward Search:} From the source node, explore only edges leading to higher-ranked nodes.
			\item \textbf{Backward Search:} From the target node, explore only edges leading to higher-ranked nodes.
			\item \textbf{Intersection Check:} Terminate when the forward and backward searches meet at a common node.
			\item \textbf{Path Reconstruction:} Combine the paths from both searches and resolve shortcuts to retrieve the actual shortest path.
		\end{itemize}
	Please refer to \textbf{Appendix \ref{appendix:contraction:correctness}} for formal Proof of correctness
	\end{enumerate}
	\subsubsection{Complexity}
	\subsubsection*{Preprocessing Complexity:}
	\begin{itemize}
		\item \textbf{Time:} \(O(n \log n + m)\), where \(n\) = number of nodes and \(m\) = number of edges.
		\item \textbf{Space:} \(O(m+s)\), where \(s\) = number of shortcuts added during preprocessing.
	\end{itemize}
	
	\subsubsection*{Query Complexity:}
	\begin{itemize}
		\item \textbf{Time:} \(O(k \log k)\), where \(k\) = number of nodes explored during the bidirectional search (typically much smaller than \(n\)).
		\item \textbf{Space:} \(O(k)\) for storing the search frontiers.
	\end{itemize}
	Please refer to \textbf{Appendix \ref{appendix:constraction:complexity}} for formal proof of Complexity.
	\subsubsection{Pros and Cons}
	\begin{enumerate}
		\item Fast Queries: Enables sub-second shortest-path computations in large graphs.  
		\item Scalability: Handles large-scale graphs (e.g., road networks with millions of nodes).
		\item  Optimality: Guarantees exact shortest paths.
		\item Efficient Storage: Shortcuts are compactly stored, minimizing memory usage.\\
		
		\item Preprocessing Overhead: Requires significant time and space for preprocessing. 
		\item Static Graphs: Not well-suited for dynamic graphs with frequent updates. 
		\item Complex Implementation: Requires careful node ordering and shortcut management. 
		\item Dependency on Hierarchy Quality: Performance depends on the node ordering heuristic.
		
	\end{enumerate}
	\subsection{A* Landmark Technique Algorithm}
		\subsubsection{Introduction}
			The ALT algorithm is a goal-directed search proposed by Golberg and Harrelson that uses the A* search algorithm and distance estimates to define node potentials that direct the search towards the target.
			It is a variant of the \textbf{A*} search algorithm where \textbf{L}andmarks and the \textbf{T}riangle inequality are used to compute for a feasible potential function. 
		\subsubsection{Algorithm}
			The ALT algorithm consists of two main phases:
			\begin{enumerate}
				\item \textbf{Preprocessing Phase}: In this phase, ALT selects a set of \textit{landmarks} and precomputes the shortest distances from these landmarks to all nodes in the graph.
				\begin{itemize}
					\item Choose a set of landmarks $ \textit{L} $ (typically high-degree or far-apart nodes).  Selection strategies:
					\begin{itemize}
						\item Select landmarks that maximize the shortest path distances between them.
						\item Choose nodes with high connectivity.
						\item Select a diverse set of nodes.
					\end{itemize}
					\item For each landmark $ L \in \textit{L} $, compute the shortest paths to all other nodes in the graph using Dijkstra’s Algorithm. Store the precomputed distances $d(L, v)$ for every node $v$.
				\end{itemize}
				\item \textbf{Query Phase}: When computing the shortest path from a source $s$ to a target $t$, ALT modifies A* search by using a heuristic based on \textit{landmark distances}.
					\begin{itemize}
						\item A* search requires a heuristic function $ h(v) $ that estimates the shortest distance from a node $ v $ to the target $ t $. ALT uses the \textit{triangle inequality} to define the heuristic as
						\begin{equation*}
							h(v) = \max_{L \in \textit{L}} \left( \left| d(L, v) - d(L, t) \right| \right)
						\end{equation*}
						where \textit{L}  is the set of selected \textit{landmarks}, $d(L, v)$ is the precomputed shortest distance from landmark $L$ to node $v$ and $d(L, t)$ is the precomputed shortest distance from landmark $L$ to the target $t$.
						\item Run A* Search with ALT heuristic.
					\end{itemize}
			\end{enumerate}
			This algorithm is mathematically predisposed to find the shortest path from a source vertex $s$ to every other vertex in the graph.
			Refer to \textbf{ Appendix \ref{appendix:ALT:correctness}} for a formal proof.
		\subsubsection{Complexity}
				\begin{itemize}
					\item Preprocessing Time Complexity: $ O(k \cdot (|V| + |E|) \log |V|) $
					\item Query Time Complexity: $ O((|V| + |E|) \log |V|)$
					\item Space Complexity: $O(k \cdot |V|)$
				\end{itemize}
				Please refer to \textbf{Appendix \ref{appendix:ALT:complexity}} for a formal proof of complexity. \medskip
				
		\subsubsection{Pros and Cons}
		\begin{itemize}
			\item Precomputed landmarks and A* heuristics speed up shortest path searches.
			\item Significant preprocessing time and memory usage, making it inefficient for frequently changing networks.
			\item Properly chosen landmarks enhance performance, but poor selection can degrade efficiency, affecting search quality.
		\end{itemize}
	\subsection{Hub Labeling}
		\subsubsection{Introduction}
		Hub Labeling (HL) is a preprocessing-based technique for efficient shortest path queries in graphs. It assigns labels to nodes, storing distances to selected hubs, enabling constant-time distance queries.
		
			\subsubsection{Algorithm}
				\begin{itemize}
					\item \textbf{Preprocessing phase}: Select a subset \( H \subseteq V \) of \( k \) nodes as hubs, based on heuristics such as high-degree nodes or random selection. For each $v \in V$, compute the shortest path distances to each hub $h \in H$, i.e., $d(v, h)$, using Dijkstra’s algorithm or another shortest path algorithm and store the distances in the hub label of node $ v $, denoted as:
					$L(v) = \{ d(v, h) \mid h \in H \}$.
					\item \textbf{Query phase}: Given a query between nodes $ s $ and $ t $, the shortest path $ d(s, t) $ can be computed as:
					\begin{equation*}
						d(s,t) = \min_{h \in H} \left( d(s,h) + d(h,t) \right)
					\end{equation*}
					where $d(s, h)$ is the distance from $s$ to hub $h$, and $d(h, t)$ is the distance from hub $h$ to $t$.
				\end{itemize}
			See \textbf{Appendix \ref{appendix:Hub Labelling:correctness}} for a formal proof of correctness of this algorithm.
				\subsubsection{Complexity}
					\begin{itemize}
						\item Preprocessing Time Complexity:  $ O(k \cdot (|V| + |E|) \log |V|) $
						\item Query Time Complexity:  $ O(k) $
						\item Space Complexity:  $ O(k \cdot |V|) $
					\end{itemize} 
			Please refer to \textbf{Appendix \ref{appendix:Hub Labelling:Complexity}} for a formal proof of complexity. 
				
				\subsubsection{Pros and Cons}
				\begin{itemize}
					\item Precomputed hub labels enable constant-time shortest path lookups.
					\item Building hub labels requires extensive computation and storage, making it unsuitable for graphs with frequent updates.
					\item Works well for large static graphs but demands significant memory.
				\end{itemize}

% Refer figure \ref{fig:label}.

\section{Summary of Findings}
%\begin{figure}[htb]
%\centering
%\includegraphics[scale=0.3]{./glider} % e.g. insert ./image for image.png in the working directory, adjust scale as necessary
%\caption{Caption here}
%\label{fig:label} % insert suitable label, this is used to refer to a fig from within the text as shown above
%\end{figure}

